{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
      "0  1000001  P00069042      F  0-17          10             A   \n",
      "1  1000001  P00248942      F  0-17          10             A   \n",
      "2  1000001  P00087842      F  0-17          10             A   \n",
      "3  1000001  P00085442      F  0-17          10             A   \n",
      "4  1000002  P00285442      M   55+          16             C   \n",
      "\n",
      "  Stay_In_Current_City_Years  Marital_Status  Product_Category  Purchase  \n",
      "0                          2               0                 3      8370  \n",
      "1                          2               0                 1     15200  \n",
      "2                          2               0                12      1422  \n",
      "3                          2               0                12      1057  \n",
      "4                         4+               0                 8      7969  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count   Dtype \n",
      "---  ------                      --------------   ----- \n",
      " 0   User_ID                     550068 non-null  int64 \n",
      " 1   Product_ID                  550068 non-null  object\n",
      " 2   Gender                      550068 non-null  object\n",
      " 3   Age                         550068 non-null  object\n",
      " 4   Occupation                  550068 non-null  int64 \n",
      " 5   City_Category               550068 non-null  object\n",
      " 6   Stay_In_Current_City_Years  550068 non-null  object\n",
      " 7   Marital_Status              550068 non-null  int64 \n",
      " 8   Product_Category            550068 non-null  int64 \n",
      " 9   Purchase                    550068 non-null  int64 \n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 42.0+ MB\n",
      "None\n",
      "            User_ID     Occupation  Marital_Status  Product_Category  \\\n",
      "count  5.500680e+05  550068.000000   550068.000000     550068.000000   \n",
      "mean   1.003029e+06       8.076707        0.409653          5.404270   \n",
      "std    1.727592e+03       6.522660        0.491770          3.936211   \n",
      "min    1.000001e+06       0.000000        0.000000          1.000000   \n",
      "25%    1.001516e+06       2.000000        0.000000          1.000000   \n",
      "50%    1.003077e+06       7.000000        0.000000          5.000000   \n",
      "75%    1.004478e+06      14.000000        1.000000          8.000000   \n",
      "max    1.006040e+06      20.000000        1.000000         20.000000   \n",
      "\n",
      "            Purchase  \n",
      "count  550068.000000  \n",
      "mean     9263.968713  \n",
      "std      5023.065394  \n",
      "min        12.000000  \n",
      "25%      5823.000000  \n",
      "50%      8047.000000  \n",
      "75%     12054.000000  \n",
      "max     23961.000000  \n",
      "Missing values in each column:\n",
      " User_ID                       0\n",
      "Product_ID                    0\n",
      "Gender                        0\n",
      "Age                           0\n",
      "Occupation                    0\n",
      "City_Category                 0\n",
      "Stay_In_Current_City_Years    0\n",
      "Marital_Status                0\n",
      "Product_Category              0\n",
      "Purchase                      0\n",
      "dtype: int64\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyisha\\AppData\\Local\\Temp\\ipykernel_14312\\2806364765.py:47: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Age'] = df['Age'].replace(age_mapping).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 55 30 48 53 40 21]\n",
      "User_ID                        int64\n",
      "Product_ID                    object\n",
      "Gender                        object\n",
      "Age                            int64\n",
      "Occupation                     int64\n",
      "City_Category                 object\n",
      "Stay_In_Current_City_Years     int64\n",
      "Marital_Status                 int64\n",
      "Product_Category               int64\n",
      "Purchase                       int64\n",
      "dtype: object\n",
      "   User_ID Product_ID Gender  Age  Occupation City_Category  \\\n",
      "0  1000001  P00069042      F    9          10             A   \n",
      "1  1000001  P00248942      F    9          10             A   \n",
      "2  1000001  P00087842      F    9          10             A   \n",
      "3  1000001  P00085442      F    9          10             A   \n",
      "4  1000002  P00285442      M   55          16             C   \n",
      "\n",
      "   Stay_In_Current_City_Years  Marital_Status  Product_Category  Purchase  \n",
      "0                           2               0                 3      8370  \n",
      "1                           2               0                 1     15200  \n",
      "2                           2               0                12      1422  \n",
      "3                           2               0                12      1057  \n",
      "4                           4               0                 8      7969  \n",
      "Cleaned data saved to 'cleaned_walmart_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# Define the ZIP file path\n",
    "zip_file_path = r\"C:\\Users\\Kyisha\\OneDrive\\Walmart Sales Data Analytics Capstone 2025\\Dataset_1.zip\"\n",
    "\n",
    "# Open the ZIP file and list its contents\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"extracted_files\")\n",
    "\n",
    "# Check extracted files path\n",
    "csv_file_path = \"extracted_files/walmart.csv\"\n",
    "\n",
    "# Load the extracted CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "print(df.info())   # View column names and data types\n",
    "\n",
    "print(df.describe())  # Summary of statistics\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Convert 'Stay_In_Current_City_Years' to numeric, replacing '4+' with 4\n",
    "df['Stay_In_Current_City_Years'] = df['Stay_In_Current_City_Years']. replace('4+', 4).astype(int)\n",
    "\n",
    "# Define mapping for age ranges\n",
    "age_mapping = {\n",
    "    '0-17': 9,    # Midpoint of 0-17\n",
    "    '18-25': 21,  # Midpoint of 18-25\n",
    "    '26-35': 30,  # Midpoint of 26-35\n",
    "    '36-45': 40,  # Midpoint of 36-45\n",
    "    '46-50': 48,  # Midpoint of 46-50\n",
    "    '51-55': 53,  # Midpoint of 51-55\n",
    "    '55+': 55     # Assume 55 as'55+'\n",
    "}\n",
    "\n",
    "# Replace age ranges with midpoint values and convert to int\n",
    "df['Age'] = df['Age'].replace(age_mapping).astype(int)\n",
    "\n",
    "# Verify conversion\n",
    "print(df['Age'].unique())  # Should show integer values\n",
    "\n",
    "print(df.dtypes)  # Check data types after conversion\n",
    "\n",
    "print(df.head()) # Display the first few rows after conversion\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df.to_csv(\"cleaned_walmart_data.csv\", index=False)\n",
    "print(\"Cleaned data saved to 'cleaned_walmart_data.csv'\")  # Confirmation message\n",
    "# End of the script\n",
    "# Note: Ensure the file paths are correct and accessible in your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
      "0      1  05-02-2010    1643690.90             0        42.31       2.572   \n",
      "1      1  12-02-2010    1641957.44             1        38.51       2.548   \n",
      "2      1  19-02-2010    1611968.17             0        39.93       2.514   \n",
      "3      1  26-02-2010    1409727.59             0        46.63       2.561   \n",
      "4      1  05-03-2010    1554806.68             0        46.50       2.625   \n",
      "\n",
      "          CPI  Unemployment  \n",
      "0  211.096358         8.106  \n",
      "1  211.242170         8.106  \n",
      "2  211.289143         8.106  \n",
      "3  211.319643         8.106  \n",
      "4  211.350143         8.106  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6435 entries, 0 to 6434\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Store         6435 non-null   int64  \n",
      " 1   Date          6435 non-null   object \n",
      " 2   Weekly_Sales  6435 non-null   float64\n",
      " 3   Holiday_Flag  6435 non-null   int64  \n",
      " 4   Temperature   6435 non-null   float64\n",
      " 5   Fuel_Price    6435 non-null   float64\n",
      " 6   CPI           6435 non-null   float64\n",
      " 7   Unemployment  6435 non-null   float64\n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 402.3+ KB\n",
      "None\n",
      "             Store  Weekly_Sales  Holiday_Flag  Temperature   Fuel_Price  \\\n",
      "count  6435.000000  6.435000e+03   6435.000000  6435.000000  6435.000000   \n",
      "mean     23.000000  1.046965e+06      0.069930    60.663782     3.358607   \n",
      "std      12.988182  5.643666e+05      0.255049    18.444933     0.459020   \n",
      "min       1.000000  2.099862e+05      0.000000    -2.060000     2.472000   \n",
      "25%      12.000000  5.533501e+05      0.000000    47.460000     2.933000   \n",
      "50%      23.000000  9.607460e+05      0.000000    62.670000     3.445000   \n",
      "75%      34.000000  1.420159e+06      0.000000    74.940000     3.735000   \n",
      "max      45.000000  3.818686e+06      1.000000   100.140000     4.468000   \n",
      "\n",
      "               CPI  Unemployment  \n",
      "count  6435.000000   6435.000000  \n",
      "mean    171.578394      7.999151  \n",
      "std      39.356712      1.875885  \n",
      "min     126.064000      3.879000  \n",
      "25%     131.735000      6.891000  \n",
      "50%     182.616521      7.874000  \n",
      "75%     212.743293      8.622000  \n",
      "max     227.232807     14.313000  \n",
      "Missing values in each column:\n",
      " Store           0\n",
      "Date            0\n",
      "Weekly_Sales    0\n",
      "Holiday_Flag    0\n",
      "Temperature     0\n",
      "Fuel_Price      0\n",
      "CPI             0\n",
      "Unemployment    0\n",
      "dtype: int64\n",
      "0\n",
      "Store            int64\n",
      "Date            object\n",
      "Weekly_Sales     int64\n",
      "Holiday_Flag     int64\n",
      "Temperature      int64\n",
      "Fuel_Price       int64\n",
      "CPI              int64\n",
      "Unemployment     int64\n",
      "dtype: object\n",
      "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
      "0      1  05-02-2010       1643691             0           42           3   \n",
      "1      1  12-02-2010       1641957             1           39           3   \n",
      "2      1  19-02-2010       1611968             0           40           3   \n",
      "3      1  26-02-2010       1409728             0           47           3   \n",
      "4      1  05-03-2010       1554807             0           46           3   \n",
      "\n",
      "   CPI  Unemployment  \n",
      "0  211             8  \n",
      "1  211             8  \n",
      "2  211             8  \n",
      "3  211             8  \n",
      "4  211             8  \n",
      "Cleaned sales data saved to 'cleaned_walmart_sales_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# Define the ZIP file path\n",
    "zip_file_path = r\"C:\\Users\\Kyisha\\OneDrive\\Walmart Sales Data Analytics Capstone 2025\\Dataset_2.zip\"\n",
    "\n",
    "# Open the ZIP file and list its contents\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"extracted_files\") \n",
    "\n",
    "# Check extracted files path\n",
    "csv_file_path = \"extracted_files/walmart_sales.csv\"\n",
    "\n",
    "# Load the extracted CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "print(df.info())   # View column names and data types\n",
    "\n",
    "print(df.describe())  # Summary of statistics\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Round and convert only numeric columns to integers\n",
    "df[numeric_cols] = df[numeric_cols].round().astype(int)\n",
    "\n",
    "# Verify conversion\n",
    "print(df.dtypes)\n",
    "\n",
    "print(df.head())  # Check if numeric values are rounded\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df.to_csv(\"cleaned_walmart_sales_data.csv\", index=False)\n",
    "print(\"Cleaned sales data saved to 'cleaned_walmart_sales_data.csv'\")  # Confirmation message\n",
    "# End of the script\n",
    "# Note: Ensure that the paths and filenames are correct for your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         index  User_ID Product_ID Gender  Age  Occupation City_Category  \\\n",
      "0            0  1000001  P00069042      F    9          10             A   \n",
      "1            1  1000001  P00248942      F    9          10             A   \n",
      "2            2  1000001  P00087842      F    9          10             A   \n",
      "3            3  1000001  P00085442      F    9          10             A   \n",
      "4            4  1000002  P00285442      M   55          16             C   \n",
      "...        ...      ...        ...    ...  ...         ...           ...   \n",
      "550063  550063  1006033  P00372445      M   53          13             B   \n",
      "550064  550064  1006035  P00375436      F   30           1             C   \n",
      "550065  550065  1006036  P00375436      F   30          15             B   \n",
      "550066  550066  1006038  P00375436      F   55           1             C   \n",
      "550067  550067  1006039  P00371644      F   48           0             B   \n",
      "\n",
      "        Stay_In_Current_City_Years  Marital_Status  Product_Category  \\\n",
      "0                                2               0                 3   \n",
      "1                                2               0                 1   \n",
      "2                                2               0                12   \n",
      "3                                2               0                12   \n",
      "4                                4               0                 8   \n",
      "...                            ...             ...               ...   \n",
      "550063                           1               1                20   \n",
      "550064                           3               0                20   \n",
      "550065                           4               1                20   \n",
      "550066                           2               0                20   \n",
      "550067                           4               1                20   \n",
      "\n",
      "        Purchase  index  Store        Date  Weekly_Sales  Holiday_Flag  \\\n",
      "0           8370    0.0    1.0  05-02-2010     1643691.0           0.0   \n",
      "1          15200    1.0    1.0  12-02-2010     1641957.0           1.0   \n",
      "2           1422    2.0    1.0  19-02-2010     1611968.0           0.0   \n",
      "3           1057    3.0    1.0  26-02-2010     1409728.0           0.0   \n",
      "4           7969    4.0    1.0  05-03-2010     1554807.0           0.0   \n",
      "...          ...    ...    ...         ...           ...           ...   \n",
      "550063       368    NaN    NaN         NaN           NaN           NaN   \n",
      "550064       371    NaN    NaN         NaN           NaN           NaN   \n",
      "550065       137    NaN    NaN         NaN           NaN           NaN   \n",
      "550066       365    NaN    NaN         NaN           NaN           NaN   \n",
      "550067       490    NaN    NaN         NaN           NaN           NaN   \n",
      "\n",
      "        Temperature  Fuel_Price    CPI  Unemployment  \n",
      "0              42.0         3.0  211.0           8.0  \n",
      "1              39.0         3.0  211.0           8.0  \n",
      "2              40.0         3.0  211.0           8.0  \n",
      "3              47.0         3.0  211.0           8.0  \n",
      "4              46.0         3.0  211.0           8.0  \n",
      "...             ...         ...    ...           ...  \n",
      "550063          NaN         NaN    NaN           NaN  \n",
      "550064          NaN         NaN    NaN           NaN  \n",
      "550065          NaN         NaN    NaN           NaN  \n",
      "550066          NaN         NaN    NaN           NaN  \n",
      "550067          NaN         NaN    NaN           NaN  \n",
      "\n",
      "[550068 rows x 20 columns]\n",
      "Total spend per user:\n",
      " User_ID\n",
      "1000001     334093\n",
      "1000002     810472\n",
      "1000003     341635\n",
      "1000004     206468\n",
      "1000005     821001\n",
      "            ...   \n",
      "1006036    4116058\n",
      "1006037    1119538\n",
      "1006038      90034\n",
      "1006039     590319\n",
      "1006040    1653299\n",
      "Name: Purchase, Length: 5891, dtype: int64\n",
      "Average spend by age group:\n",
      " Age\n",
      "9     8933.464640\n",
      "21    9169.663606\n",
      "30    9252.690633\n",
      "40    9331.350695\n",
      "48    9208.625697\n",
      "53    9534.808031\n",
      "55    9336.280459\n",
      "Name: Purchase, dtype: float64\n",
      "Average spend by age group (rounded):\n",
      " Age\n",
      "9     8933\n",
      "21    9170\n",
      "30    9253\n",
      "40    9331\n",
      "48    9209\n",
      "53    9535\n",
      "55    9336\n",
      "Name: Purchase, dtype: int64\n",
      "Total sales during holidays:\n",
      " Holiday_Flag\n",
      "0    6231919429\n",
      "1     505299550\n",
      "Name: Weekly_Sales, dtype: int64\n",
      "Combined data saved to 'combined_walmart_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSVs\n",
    "df1 = pd.read_csv(\"cleaned_walmart_data.csv\")\n",
    "df2 = pd.read_csv(\"cleaned_walmart_sales_data.csv\")\n",
    "\n",
    "# Reset index to create an artificial key\n",
    "df1.reset_index(inplace=True)\n",
    "df2.reset_index(inplace=True)\n",
    "\n",
    "# Merge on the newly created index\n",
    "df_combined = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# Print result\n",
    "print(df_combined)\n",
    "\n",
    "# Analysis of the combined data\n",
    "# Customer spending\n",
    "total_spend = df1.groupby(\"User_ID\")[\"Purchase\"].sum()\n",
    "print(\"Total spend per user:\\n\", total_spend)\n",
    "\n",
    "# Average spent by age group\n",
    "avg_spend_age = df1.groupby(\"Age\")[\"Purchase\"].mean()\n",
    "print(\"Average spend by age group:\\n\", avg_spend_age)\n",
    "\n",
    "# Round the average spent by age group to the nearest integer\n",
    "avg_spend_age = df1.groupby(\"Age\")[\"Purchase\"].mean().round(0).astype(int)\n",
    "print(\"Average spend by age group (rounded):\\n\", avg_spend_age)\n",
    "\n",
    "# Total sales holiday and non-holiday\n",
    "sales_holiday = df2.groupby(\"Holiday_Flag\")[\"Weekly_Sales\"].sum()\n",
    "print(\"Total sales during holidays:\\n\", sales_holiday)\n",
    "\n",
    "# save the combined DataFrame to a new CSV file\n",
    "df_combined.to_csv(\"combined_walmart_data.csv\", index=False)\n",
    "print(\"Combined data saved to 'combined_walmart_data.csv'\")  # Confirmation message\n",
    "# End of the script\n",
    "# Note: Ensure that the paths and filenames are correct for your environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
